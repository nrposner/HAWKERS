{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d13b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "from collections import defaultdict\n",
    "\n",
    "data = pd.read_csv(\"data/service_reviews_15000rows_translated.csv\")\n",
    "\n",
    "queries = [\"Customer service\", \"Delivery service\", \"Product Quality\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3cb9d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The following cells contain a naive text classifier using query similarity. Using LSI (Latent Semantic Indexing), we group text into several topics and test the similarity of that text to provided queries. In this case, the queries are 'Customer service', 'Delivery service' and 'Product quality', the three major topics into which we want to classify the text. \n",
    "\n",
    "This is not a finished product: it is a prototype that still requires refinement, especially in selection of the number of topics and evaluation. However, this should serve as a proof of concept. It is presently classifying ~15k customer reviews translated into English. \n",
    "\n",
    "**Requires:** Numpy, Pandas, Gensim\n",
    "\n",
    "**Approximate time to run:** <5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "025c4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_extractor():\n",
    "    \"\"\"Pulls out the ninth column from the dataset in order to get\n",
    "    the raw corpus which will be use din preprocessing\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(\"data/service_reviews_15000rows_translated.csv\")\n",
    "    corpus = data.iloc[:, 8]\n",
    "    return corpus\n",
    "\n",
    "def preprocess(corpus:pd.core.series.Series, min_len:int = 3, max_len:int = 15) -> list:\n",
    "    \"\"\" Take in a corpus of text in a pandas series and perform\n",
    "    preprocessing\n",
    "\n",
    "    corpus: a pandas series containing text\n",
    "\n",
    "    min_len: minimum word length. No shorter words will be retained\n",
    "\n",
    "    max_len: maximum word length. No longer words will be retained\n",
    "    \"\"\"\n",
    "    \n",
    "    if not (min_len <= max_len):\n",
    "        raise ValueError(\"make sure your minimum and maximum token lengths are not reversed\")\n",
    "\n",
    "    preprocessed_corpus = []\n",
    "\n",
    "    for i in corpus:\n",
    "        preprocessed_doc = gensim.utils.simple_preprocess(i, min_len = min_len, max_len = max_len)\n",
    "    \n",
    "        preprocessed_corpus.append(preprocessed_doc)\n",
    "\n",
    "        # go line by line, removing common words\n",
    "    stoplist = set('for a of the and to in'.split(' '))\n",
    "    texts = [[word for word in document if word not in stoplist]\n",
    "         for document in preprocessed_corpus]\n",
    "\n",
    "    # count word frequencies\n",
    "    frequency = defaultdict(int)\n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency[token] += 1\n",
    "\n",
    "    # only keep words that appear more than once\n",
    "    processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "\n",
    "    return processed_corpus\n",
    "\n",
    "def corpus_maker(processed_corpus:list):\n",
    "    \"\"\" Take in a processed corpus from preprocessing and transform it into\n",
    "    a tfidf bag of words corpus\n",
    "    \n",
    "    \"\"\"\n",
    "    # turn this into a dictionary structure\n",
    "    dictionary = corpora.Dictionary(processed_corpus)\n",
    "\n",
    "    # create a 'bag of words' corpus using that dictionary\n",
    "    bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "\n",
    "    # train the model\n",
    "\n",
    "    # tfidf is a transformation that finds term frequency in model frequency\n",
    "    # we will use this in order to create a structure which other models can attack more easily\n",
    "    tfidf = models.TfidfModel(bow_corpus)\n",
    "\n",
    "    corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "    return corpus_tfidf, dictionary\n",
    "\n",
    "def similarity_order(corpus_tfidf: gensim.interfaces.TransformedCorpus, dictionary: gensim.corpora.dictionary.Dictionary, queries:list[str], mod, num_topics:int):\n",
    "    \"\"\" Take in a tfidf corpus and dictionary created by corpus_creation,\n",
    "    as well as a query such as 'customer support' and a model. Then we \n",
    "    classify each document in the corpus according to which query\n",
    "    had the highest similarity score\n",
    "    This remains a naive classifier, more refinement is needed. LSI model is recommended\n",
    "\n",
    "    mod: must be formatted as models.ModelName, such as models.LdaModel, or models.LsiModel\n",
    "    \"\"\"\n",
    "\n",
    "    model = mod(corpus_tfidf, id2word=dictionary, num_topics=num_topics)\n",
    "    \n",
    "    query_scores = []\n",
    "    \n",
    "    df = pd.DataFrame(columns = queries)\n",
    "    \n",
    "    for q in queries:\n",
    "        vec_bow = dictionary.doc2bow(q.lower().split())\n",
    "        vec_model = model[vec_bow]  # convert the query to LSI space\n",
    "\n",
    "        #index these\n",
    "        index = similarities.MatrixSimilarity(model[corpus_tfidf])\n",
    "\n",
    "        sims = index[vec_model]  # perform a similarity query against the corpus\n",
    "        \n",
    "        query_scores.append(sims)\n",
    "        \n",
    "        df[q] = sims\n",
    "\n",
    "    df[\"class\"] = df.idxmax(axis=1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d29694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_pipeline(data, queries, mod, num_topics):\n",
    "    corpus = corpus_extractor()\n",
    "    processed_corpus = preprocess(corpus)\n",
    "    corpus_tfidf, dictionary = corpus_maker(processed_corpus)\n",
    "    \n",
    "    df = similarity_order(corpus_tfidf, dictionary, queries, mod, num_topics)\n",
    "    \n",
    "    df[\"text\"] = corpus\n",
    "    \n",
    "    queries = queries\n",
    "\n",
    "    bins = []\n",
    "\n",
    "    for q in queries:\n",
    "        subset = df[df[\"class\"]==q]\n",
    "        bins.append(subset[\"text\"].values)\n",
    "    \n",
    "    classes_dict = {}\n",
    "    for q, b in zip(queries, bins):\n",
    "        key, value = q, b\n",
    "        classes_dict[key] = value\n",
    "        \n",
    "    return classes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ac82312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.28 s, sys: 4.41 s, total: 12.7 s\n",
      "Wall time: 2.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifications = classification_pipeline(data, queries, models.LsiModel, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b5f658",
   "metadata": {},
   "source": [
    "Below are some of the comments classified as 'Customer service' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57baf9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Good evening, I received the order and one glass was missing, I have sent through the site and no one has answered me.',\n",
       "       'Great, super pretty glasses. and good material',\n",
       "       \"I was a Hawkers customer and thought it was a trustworthy brand, but it wasn't. \\n\\nOn November 19th I placed two repeat orders (my mistake) and then tried to cancel one of them (unsuccessfully). I sent an email and they told me not to accept the order at home as it would be returned (and it was). \\n\\nTo date, I have sent 3 emails demanding a refund and still nothing! They have the glasses and my money (65).\\n\\nUntil reasons to the contrary, I do not recommend this brand TO ANYONE!!!\\n\\nThere's no point in saying to report the problem at the link because I've already done it!\\n\\n\\n\\nUpdate: I haven't received my refund yet. I received an email saying that they had refunded me but I still haven't received the money.\",\n",
       "       ...,\n",
       "       'The price is good but some glasses arrived with a fallen glass. Even if they are worth 18 euros, they should last at least a day!',\n",
       "       '2 time I order and incredible',\n",
       "       'I bought others at AC and for much less $ they included a hard case and cleaning cloth. The decals are not an added value, you could save them.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications[\"Customer service\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272676e",
   "metadata": {},
   "source": [
    "Below are some of the comments classified as 'Delivery service' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf91c66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fast and good delivery!',\n",
       "       \"Everything was fast and correct. I'm not giving it 5 stars because they seem a bit dark to me.\\n\\nThat's what happens when you buy things online without trying them on first!!\",\n",
       "       'Fast and recommended', ...,\n",
       "       'This company did not send a confirmation email of my order, then my order went \"missing\" from the delivery service. Would not recommend.',\n",
       "       '... top quality.\\n\\nawesome products, profesionalism and short time for delivery.',\n",
       "       'Fast delivery, top quality'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications[\"Delivery service\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a98971",
   "metadata": {},
   "source": [
    "Below are some of the comments classified as 'Product quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f90d79a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I love the quality of the glasses!',\n",
       "       'I ordered a pair of sunglasses from their wide selection, I was able to benefit from a special advantage and get 2 pairs for the price of one. I find the quality/price ratio very good and the shipping went well, fast reception.\\n\\n\\n\\nI will not hesitate to order again.',\n",
       "       'Correct for summer and the beach', ...,\n",
       "       'Good value for money. Good designs!',\n",
       "       'Good glasses, good promotions, good prices and good delivery service.',\n",
       "       'Everything great quality price and fast shipping, a ten'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications[\"Product Quality\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85801321",
   "metadata": {},
   "source": [
    "## Further Notes\n",
    "\n",
    "We note that, at present, we are only classifying the reviews into the three aforementioned categories. At present we do not account for reviews which do not belong to any of the three categories. \n",
    "\n",
    "We further note that many of the reviews, particularly the positive ones, could be plausibly placed in multiple categories. For example, the review 'Good glasses, good promotions, good prices and good delivery service.' was classified as 'Product quality', but could have easily been classified under 'Delivery service' as well. \n",
    "\n",
    "Solutions to these issues will depend on how we ultimately plan to implement this. In particular, I assume that proper classification of and quick response to positive reviews is not as important as for negative reviews, so issues like the one above may or may not be important to address. Work continues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d3b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
